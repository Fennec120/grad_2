{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8849230",
   "metadata": {},
   "source": [
    "# ooookay you motherfuckers!\n",
    "lets roll!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e9fca",
   "metadata": {},
   "source": [
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b70e74",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"xyi\") \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bfb46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "# scoring\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# drawing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# estimators\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f98067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_df(part):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    # open\n",
    "    df = pd.read_csv('train_data/tst_'+str(part)+'.csv', header=None)\n",
    "    \n",
    "    # очень неудобные названия\n",
    "    col_names = dict()\n",
    "    for i in range(len(df.columns)):\n",
    "                       col_names[df.columns[i]] = cols[i]\n",
    "    df = df.rename(columns=col_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16754c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df(df3, total_rows =  100000, neg_percent = 50, pos_percent = 50):\n",
    "#     print( 'sample_df3 start')\n",
    "    df3_pos = df3[df3['flag'] == 1].sample(int(total_rows / 100 * pos_percent))\n",
    "    df3_neg = df3[df3['flag'] == 0].sample(int(total_rows / 100 * neg_percent))\n",
    "    df3_pos = df3_pos.reset_index()\n",
    "    df3_neg = df3_neg.reset_index()\n",
    "    df3_pos = df3_pos.drop('index', axis=1)\n",
    "    df3_neg = df3_neg.drop('index', axis=1)\n",
    "    df3 = pd.concat([df3_pos, df3_neg])\n",
    "    \n",
    "#     print( 'sample_df3 end')\n",
    "#     print('-')      \n",
    "#     print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3229c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb8925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'rn', 'pre_since_opened', 'pre_since_confirmed', 'pre_pterm', 'pre_fterm', 'pre_till_pclose', 'pre_till_fclose', 'pre_loans_credit_limit', 'pre_loans_next_pay_summ',\n",
    " 'pre_loans_outstanding', 'pre_loans_total_overdue', 'pre_loans_max_overdue_sum', 'pre_loans_credit_cost_rate', 'pre_loans5', 'pre_loans530', 'pre_loans3060', 'pre_loans6090', 'pre_loans90', 'is_zero_loans5',\n",
    " 'is_zero_loans530', 'is_zero_loans3060', 'is_zero_loans6090', 'is_zero_loans90', 'pre_util', 'pre_over2limit', 'pre_maxover2limit', 'is_zero_util', 'is_zero_over2limit', 'is_zero_maxover2limit', 'enc_paym_0',\n",
    " 'enc_paym_1', 'enc_paym_2', 'enc_paym_3', 'enc_paym_4', 'enc_paym_5', 'enc_paym_6', 'enc_paym_7', 'enc_paym_8', 'enc_paym_9', 'enc_paym_10', 'enc_paym_11','enc_paym_12', 'enc_paym_13', 'enc_paym_14', 'enc_paym_15',\n",
    " 'enc_paym_16', 'enc_paym_17', 'enc_paym_18', 'enc_paym_19', 'enc_paym_20', 'enc_paym_21', 'enc_paym_22', 'enc_paym_23', 'enc_paym_24', 'enc_loans_account_holder_type', 'enc_loans_credit_status','enc_loans_credit_type', 'enc_loans_account_cur', 'pclose_flag',\n",
    " 'fclose_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb35835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_df(0)\n",
    "df2 = open_df(1)\n",
    "df3 = open_df(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2644df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv('train_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09d4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, answers, on='id', how='left')\n",
    "df2 = pd.merge(df2, answers, on='id', how='left')\n",
    "df3 = pd.merge(df3, answers, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106430f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc9c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n"
     ]
    }
   ],
   "source": [
    "df.loc[df.id == 495, 'rn'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beab670",
   "metadata": {},
   "source": [
    "# 1 гиппотеза. Сбалансировать таргет 50/50 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84bff417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_df3 start\n",
      "sample_df3 end\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "df_balanced = sample_df(df, 100000, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5938a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b39eba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "]\n",
    "#     xgb(),\n",
    "#     lgb(),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1913f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_balanced.drop('flag', axis=1)\n",
    "y = df_balanced['flag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "563732c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    cv_scores = cross_val_score(model, x, y, cv=3, scoring='roc_auc')\n",
    "    results_dict[str(model)[0:str(model).find('(')]] = mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1fcae37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': 0.800007655519486,\n",
       " 'SVC': 0.5037922246810788,\n",
       " 'RandomForestClassifier': 0.6497169063555427,\n",
       " 'MLPClassifier': 0.5475719430597831,\n",
       " 'LogisticRegression': 0.5050264873199198,\n",
       " 'DecisionTreeClassifier': 0.5506800682419088,\n",
       " 'GaussianNB': 0.5812535989447697}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5b86e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score: 0.6616983112883607\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bc3e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5, p=2, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3254480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(weights='distance')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da71b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df2.drop('flag', axis=1)\n",
    "y_test = df2['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f894afa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.5000392120700018\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd374bf6",
   "metadata": {},
   "source": [
    "## результат\n",
    "нихуя не работает:\n",
    "ни одна из моделей не дала сколько нибудь интересной метрики за исключением:\n",
    "1) KNN - при CV в рамках одного сета дает ахуевшие 0,8 без инжиниринга без нихуя, но на другом сете - 0,5 и отъебись - а я то уж обрадовался:((\n",
    "2) лес дает скромные 0,65 - в теории если бы нашлась еще одна модель, которая хотя бы сносно что то предсказывала - можно было бы попробовать заставить их работать в паре\n",
    "\n",
    "подробнее в блокноте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb35176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d5d8b7c",
   "metadata": {},
   "source": [
    "# 2 гиппотеза.  Берем последний продукт для каждого id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb64aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(df.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca06f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    id_list = []\n",
    "    with open('id_list_0.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            id_list.append(\n",
    "                (\n",
    "                    eval(line.strip().split(', ')[0].replace('(','')), \n",
    "                    eval(line.strip().split(', ')[1].replace(')',''))\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    \n",
    "except FileNotFoundError:\n",
    "    \n",
    "    id_list = list(df.id.unique())\n",
    "    for entry in range(len(id_list)):\n",
    "        id_list[entry] =(id_list[entry], max(df[df.id == id_list[entry]].rn))\n",
    "\n",
    "    with open('id_list_0.txt', 'w') as file:\n",
    "        for item in id_list:\n",
    "            file.write(str( item)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eddf797d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21b0a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = df[(df.id == id_list[0][0] )& (df.rn == id_list[0][1])]\n",
    "for i in range(len(id_list)):\n",
    "    new_row = df[(df.id == id_list[i][0])& (df.rn == id_list[i][1])]\n",
    "    df_cut = pd.concat([df_cut, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6acc8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = df_cut.drop(0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6161d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = pd.read_csv('train_data/df_only_last_product_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abd5855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.to_csv('train_data/df_only_last_product_0.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e56c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ffa374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "]\n",
    "#     xgb(),\n",
    "#     lgb(),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd536407",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_cut.drop('flag', axis=1)\n",
    "y = df_cut['flag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbddc52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c74f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    cv_scores = cross_val_score(model, x, y, cv=3, scoring='roc_auc')\n",
    "    results_dict[str(model)[0:str(model).find('(')]] = mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "83f46ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': 0.5014837697443463,\n",
       " 'SVC': 0.5041829161493093,\n",
       " 'RandomForestClassifier': 0.6342966486892172,\n",
       " 'MLPClassifier': 0.4885521343602927,\n",
       " 'LogisticRegression': 0.5325920477964842,\n",
       " 'DecisionTreeClassifier': 0.5332065228519628,\n",
       " 'GaussianNB': 0.6265383537138974}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ce44609",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\tree\\_classes.py:248\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[1;32m--> 248\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n\u001b[0;32m    250\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3943e1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.5835822646171664\n"
     ]
    }
   ],
   "source": [
    "x_test = df2.drop('flag', axis=1)\n",
    "y_test = df2['flag']\n",
    "y_pred_prob = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "465d8294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Score: 0.6811226032781477\n"
     ]
    }
   ],
   "source": [
    "# model = RandomForestClassifier()\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8298c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=10,\n",
       "                       n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=10,\n",
       "                       n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=10,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_leaf=4, min_samples_split=10)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a957c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.6314349390953861\n"
     ]
    }
   ],
   "source": [
    "x_test = df2.drop('flag', axis=1)\n",
    "y_test = df2['flag']\n",
    "y_pred_prob = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe552d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "317062c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_id_rn = df2[['id','rn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04dd734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list_1 = list(df2_id_rn.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86247f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    id_list_1 = []\n",
    "    with open('id_list_1.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            id_list_1.append(\n",
    "                (\n",
    "                    eval(line.strip().split(', ')[0].replace('(','')), \n",
    "                    eval(line.strip().split(', ')[1].replace(')',''))\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    \n",
    "except FileNotFoundError:\n",
    "    \n",
    "    id_list_1 = list(df2_id_rn.id.unique())\n",
    "    for entry in range(len(id_list_1)):\n",
    "        id_list_1[entry] =(id_list_1[entry], max(df2_id_rn[df2_id_rn.id == id_list_1[entry]].rn))\n",
    "\n",
    "    with open('id_list_1.txt', 'w') as file:\n",
    "        for item in id_list_1:\n",
    "            file.write(str( item)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8e34e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut_1 = df2[(df2.id == id_list_1[0][0] )& (df2.rn == id_list_1[0][1])]\n",
    "for i in range(len(id_list_1)):\n",
    "    new_row = df2[(df2.id == id_list_1[i][0])& (df2.rn == id_list_1[i][1])]\n",
    "    df_cut_1 = pd.concat([df_cut_1, new_row], ignore_index=True)\n",
    "df_cut_1.to_csv('train_data/df_only_last_product_1.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99d54f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut_1 = pd.read_csv('train_data/df_only_last_product_1.csv')\n",
    "df_cut_1 = df_cut_1.drop(0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7ec5d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_paym_22</th>\n",
       "      <th>enc_paym_23</th>\n",
       "      <th>enc_paym_24</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>enc_loans_credit_status</th>\n",
       "      <th>enc_loans_credit_type</th>\n",
       "      <th>enc_loans_account_cur</th>\n",
       "      <th>pclose_flag</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250000</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250001</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250002</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250003</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250004</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>499995</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>499996</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>499997</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>499998</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250000</th>\n",
       "      <td>499999</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  \\\n",
       "1       250000   7                11                    9          4   \n",
       "2       250001  11                 7                    5          6   \n",
       "3       250002   3                 9                    6          4   \n",
       "4       250003   2                10                   12          4   \n",
       "5       250004   2                19                    0          1   \n",
       "...        ...  ..               ...                  ...        ...   \n",
       "249996  499995   3                19                    9          4   \n",
       "249997  499996   9                19                    0         14   \n",
       "249998  499997   9                 9                   13         15   \n",
       "249999  499998   9                 7                    9          4   \n",
       "250000  499999  12                12                    2          6   \n",
       "\n",
       "        pre_fterm  pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "1               8                1               11                       0   \n",
       "2               1                0                4                      15   \n",
       "3               8                1               11                       1   \n",
       "4              13                1                7                      14   \n",
       "5               8               14               11                       8   \n",
       "...           ...              ...              ...                     ...   \n",
       "249996          8                1               11                       7   \n",
       "249997          8               10               11                      15   \n",
       "249998         12                1               11                      12   \n",
       "249999          8                1               11                       6   \n",
       "250000          8                0               11                       2   \n",
       "\n",
       "        pre_loans_next_pay_summ  ...  enc_paym_22  enc_paym_23  enc_paym_24  \\\n",
       "1                             5  ...            3            3            4   \n",
       "2                             3  ...            3            3            4   \n",
       "3                             1  ...            3            3            4   \n",
       "4                             2  ...            3            3            4   \n",
       "5                             2  ...            3            3            4   \n",
       "...                         ...  ...          ...          ...          ...   \n",
       "249996                        0  ...            3            3            4   \n",
       "249997                        5  ...            3            3            4   \n",
       "249998                        1  ...            3            3            4   \n",
       "249999                        6  ...            3            3            4   \n",
       "250000                        5  ...            3            3            4   \n",
       "\n",
       "        enc_loans_account_holder_type  enc_loans_credit_status  \\\n",
       "1                                   1                        2   \n",
       "2                                   1                        2   \n",
       "3                                   1                        2   \n",
       "4                                   1                        3   \n",
       "5                                   1                        2   \n",
       "...                               ...                      ...   \n",
       "249996                              1                        2   \n",
       "249997                              1                        2   \n",
       "249998                              1                        2   \n",
       "249999                              1                        2   \n",
       "250000                              1                        2   \n",
       "\n",
       "        enc_loans_credit_type  enc_loans_account_cur  pclose_flag  \\\n",
       "1                           3                      1            1   \n",
       "2                           0                      1            0   \n",
       "3                           3                      1            1   \n",
       "4                           1                      1            1   \n",
       "5                           4                      1            0   \n",
       "...                       ...                    ...          ...   \n",
       "249996                      3                      1            1   \n",
       "249997                      4                      1            0   \n",
       "249998                      4                      1            0   \n",
       "249999                      4                      1            1   \n",
       "250000                      0                      1            0   \n",
       "\n",
       "        fclose_flag  flag  \n",
       "1                 1     0  \n",
       "2                 0     0  \n",
       "3                 1     0  \n",
       "4                 0     0  \n",
       "5                 1     0  \n",
       "...             ...   ...  \n",
       "249996            1     0  \n",
       "249997            1     0  \n",
       "249998            0     0  \n",
       "249999            1     1  \n",
       "250000            1     0  \n",
       "\n",
       "[250000 rows x 62 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cut_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549957af",
   "metadata": {},
   "source": [
    "## результат \n",
    "ничего выдающегося\n",
    "1) после грида валидация леса на новых данных дает 0,63\n",
    "2) близко к лесу первичный поиск дает только некий gaussianDB но я не знаю что это такое, по этому пока не влезал - в конце концов метрика меньше, надеюсь дело не в рандомном разлете и я не пропустил сейчас выйгрышный билет\n",
    "3) кажется придется все же разобраться с бустингом и/или рано или поздно прикрутить голосование\n",
    "4) пидорская млп не работает - я помню так она меня выручила в первой курсовой:("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208b8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce6eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd5c0b29",
   "metadata": {},
   "source": [
    "#  3 гиппотеза.  взять последний продукт для каждого id, смерджить пару сетов, сбалансировать, т.к. иначе очень большая получится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9162bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut_merged = pd.concat([df_cut, df_cut_1], ignore_index=True)\n",
    "df_cut_merged = df_cut_merged.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "845c6de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_df3 start\n",
      "sample_df3 end\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "df_cut_merged = sample_df(df_cut_merged,df_cut_merged.flag.value_counts()[1], 50,50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "803204a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_cut_merged.drop('flag', axis=1)\n",
    "y = df_cut_merged.flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029fc0f",
   "metadata": {},
   "source": [
    "## а теперь все вместе, чтобы можно было оставить на полдня:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf7b4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем список для результатов\n",
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# задать варианты балансировки - 50%, 45% положительных и т.д.\n",
    "shares = [50, 45, 40 ,35, 30, 25, 20, 15, 10, 5]\n",
    "\n",
    "for i in shares:\n",
    "    results_dict = dict()\n",
    "    df_cut_merged = pd.concat([df_cut, df_cut_1], ignore_index=True)\n",
    "    df_cut_merged = df_cut_merged.drop(['id'], axis=1)\n",
    "    df_cut_merged = sample_df(\n",
    "        df_cut_merged, \n",
    "        round(df_cut_merged.flag.value_counts()[1] / i * 100 + 1, 0),\n",
    "        100 - i,\n",
    "        i\n",
    "    )\n",
    "    \n",
    "    # пройтись по всем моделям и записать результаты в словарь\n",
    "    models = [\n",
    "        KNeighborsClassifier(),\n",
    "        SVC(),\n",
    "        RandomForestClassifier(),\n",
    "        MLPClassifier(),\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        GaussianNB(),\n",
    "    ]\n",
    "    #     xgb(),\n",
    "    #     lgb(),\n",
    "    # ]\n",
    "    x = df_cut_merged.drop('flag', axis=1)\n",
    "    y = df_cut_merged.flag\n",
    "    \n",
    "    for model in models:\n",
    "    \n",
    "        cv_scores = cross_val_score(model, x, y, cv=3, scoring='roc_auc')\n",
    "        results_dict[str(model)[0:str(model).find('(')]] = mean(cv_scores)\n",
    "\n",
    "\n",
    "    # и добавить словарь в список словарей с результатами вместе с описанием доли\n",
    "    results_list.append(f'share is {i}')\n",
    "    results_list.append(results_dict)\n",
    "    print('share ', i,' is done')\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('share is ',i, ', df size is ', df_cut_merged.shape, ' pos flag is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c9a44",
   "metadata": {},
   "source": [
    "## параллельно попробуем запустить разовое обучение на сете 50/50 и опробуем на третьем сете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc502bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = pd.read_csv('train_data/df_only_last_product_0.csv')\n",
    "df_cut_1 = pd.read_csv('train_data/df_only_last_product_1.csv')\n",
    "df_cut_merged = pd.concat([df_cut, df_cut_1], ignore_index=True)\n",
    "df_cut_merged = df_cut_merged.drop(['id'], axis=1)\n",
    "df_cut_merged = sample_df(df_cut_merged, df_cut_merged.flag.value_counts()[1] * 2, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a32447a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_cut_merged.drop('flag', axis=1)\n",
    "y = df_cut_merged.flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ff08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "        KNeighborsClassifier(),\n",
    "        SVC(),\n",
    "        RandomForestClassifier(),\n",
    "        MLPClassifier(),\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        GaussianNB(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48df0bc2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict()\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    cv_scores = cross_val_score(model, x, y, cv=3, scoring='roc_auc')\n",
    "    results_dict[str(model)[0:str(model).find('(')]] = mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb893dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': 0.6082156920067399,\n",
       " 'SVC': 0.680661354978124,\n",
       " 'RandomForestClassifier': 0.6853091487422303,\n",
       " 'MLPClassifier': 0.666758333025849,\n",
       " 'LogisticRegression': 0.6783188926211895,\n",
       " 'DecisionTreeClassifier': 0.5657900367690957,\n",
       " 'GaussianNB': 0.6506747711100201}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27c56376",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "#         KNeighborsClassifier(),\n",
    "        SVC(probability=True),\n",
    "        RandomForestClassifier(),\n",
    "        MLPClassifier(),\n",
    "        LogisticRegression(),\n",
    "#         DecisionTreeClassifier(),\n",
    "#         GaussianNB(),\n",
    "    ]\n",
    "\n",
    "x = df_cut_merged.drop('flag', axis=1)\n",
    "y = df_cut_merged.flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cb0eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_2_stage = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d82ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = open_df(2)\n",
    "df3 = pd.merge(df3, answers, on='id', how='left')\n",
    "df3 = df3.drop('id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f7cb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df3.drop('flag', axis=1)\n",
    "y_test = df3['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5995e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(x,y)\n",
    "    y_pred_prob = model.predict_proba(x_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    results_dict_2_stage[str(model)[0:str(model).find('(')]] = roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c4f57c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVC': 0.6126069032681178,\n",
       " 'RandomForestClassifier': 0.6246506905604878,\n",
       " 'MLPClassifier': 0.6034057912225304,\n",
       " 'LogisticRegression': 0.6119021451189127}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict_2_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bffcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8585e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2cc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154cceb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c67568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87971884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8105b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1210b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51633b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906dbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309ad60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d73cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4a618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbe7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef95876",
   "metadata": {},
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5, p=2, weights='distance')\n",
    "model.fit(x,y)\n",
    "x_test = df2.drop('flag', axis=1)\n",
    "y_test = df2['flag']\n",
    "y_pred_prob = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adfb5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2b929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072d314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6750fe80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcfcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b432476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = dict()\n",
    "for col in cols:\n",
    "    new_row[col] = list(df.loc[df['id'] == 0,col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e43cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row_df = pd.DataFrame.from_records(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f849e8f",
   "metadata": {},
   "source": [
    "new_row_df.iloc[1,1] = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89500505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  flag\n",
       "0              0     0\n",
       "1              1     0\n",
       "2              2     0\n",
       "3              3     0\n",
       "4              4     0\n",
       "...          ...   ...\n",
       "2999995  2999995     0\n",
       "2999996  2999996     0\n",
       "2999997  2999997     0\n",
       "2999998  2999998     0\n",
       "2999999  2999999     0\n",
       "\n",
       "[3000000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af9739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20522364",
   "metadata": {},
   "source": [
    "sns.heatmap(df_balanced.corr(), cmap='coolwarm', linewidths=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664882b4",
   "metadata": {},
   "source": [
    "df_corr = df_balanced.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d957c25",
   "metadata": {},
   "source": [
    "columns = df_corr.columns\n",
    "rows = df_corr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d283b06",
   "metadata": {},
   "source": [
    "results_acc = [[]]*len(threshholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92351ef",
   "metadata": {},
   "source": [
    "results_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3b32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b1758c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshhold is  0.01\n",
      "0  fits done in loop  0\n",
      "1  fits done in loop  0\n",
      "2  fits done in loop  0\n",
      "threshhold is  0.05\n",
      "0  fits done in loop  1\n",
      "1  fits done in loop  1\n",
      "2  fits done in loop  1\n",
      "threshhold is  0.08\n",
      "0  fits done in loop  2\n",
      "1  fits done in loop  2\n",
      "2  fits done in loop  2\n"
     ]
    }
   ],
   "source": [
    "threshholds = [0.01, 0.05, 0.08]#,[0.02, 0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "results_acc = [[]]*len(threshholds)\n",
    "results_roc = [[]]*len(threshholds)\n",
    "counter = 0\n",
    "for entry_1 in threshholds:\n",
    "    \n",
    "    print('threshhold is ', entry_1)\n",
    "\n",
    "    corrs = []\n",
    "    for col in columns:\n",
    "        corrs.append((df_balanced.flag.corr(df_balanced[col]), col))\n",
    "    corrs = corrs[:-1]\n",
    "    corrs = sorted(corrs)\n",
    "\n",
    "\n",
    "    significant_cols = []\n",
    "\n",
    "    threshhold = entry_1\n",
    "\n",
    "    for entry in corrs:\n",
    "        if entry[0] < -threshhold or entry[0] > threshhold:\n",
    "            significant_cols.append(entry[1])\n",
    "    significant_cols.append('flag')\n",
    "    \n",
    "    \n",
    "    df_balanced_cut = df_balanced[significant_cols]\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        df_train, df_test = train_test_split(df_balanced_cut, stratify=df_balanced_cut['flag'], test_size=0.3)\n",
    "\n",
    "        x_train = df_train.drop('flag', axis=1)\n",
    "        y_train = df_train.flag\n",
    "        x_test = df_test.drop('flag', axis=1)\n",
    "        y_test = df_test.flag\n",
    "\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "        pred_train = model.predict(x_train)\n",
    "        pred_test = model.predict(x_test)\n",
    "    #     print('train score acc - ', accuracy_score(y_train, pred_train))\n",
    "    #     print('test score acc - ', accuracy_score(y_test, pred_test))\n",
    "        results_acc[counter].append(accuracy_score(y_test, pred_test))\n",
    "\n",
    "\n",
    "        prob_train = model.predict_proba(x_train)[:, 1]\n",
    "        prob_test = model.predict_proba(x_test)[:, 1]\n",
    "    #     print('train score roc - ', roc_auc_score(y_train, prob_train))\n",
    "    #     print('test score roc - ', roc_auc_score(y_test, prob_test))\n",
    "        results_roc[counter].append(roc_auc_score(y_test, prob_test))\n",
    "        \n",
    "        print(i, ' fits done in loop ', counter)\n",
    "\n",
    "\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c73587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c5b6001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6377428977777777,\n",
       "  0.6372906488888889,\n",
       "  0.6340239244444446,\n",
       "  0.609586251111111,\n",
       "  0.6111367733333335,\n",
       "  0.6120779888888889,\n",
       "  0.60261152,\n",
       "  0.5999410177777779,\n",
       "  0.6023576733333333],\n",
       " [0.6377428977777777,\n",
       "  0.6372906488888889,\n",
       "  0.6340239244444446,\n",
       "  0.609586251111111,\n",
       "  0.6111367733333335,\n",
       "  0.6120779888888889,\n",
       "  0.60261152,\n",
       "  0.5999410177777779,\n",
       "  0.6023576733333333],\n",
       " [0.6377428977777777,\n",
       "  0.6372906488888889,\n",
       "  0.6340239244444446,\n",
       "  0.609586251111111,\n",
       "  0.6111367733333335,\n",
       "  0.6120779888888889,\n",
       "  0.60261152,\n",
       "  0.5999410177777779,\n",
       "  0.6023576733333333]]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70aeb3b",
   "metadata": {},
   "source": [
    "for i in range(len(results_roc)):\n",
    "    print('for threshhold ',threshholds[i], ' avg is ', results_roc[i].mean())\n",
    "for i in range(len(results_roc)):\n",
    "    print('for threshhold ',threshholds[i], ' avg is ', results_acc[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf171a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36914a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5da8971f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df676ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_balanced, stratify=df_balanced['flag'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8395146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop('flag', axis=1)\n",
    "y_train = df_train.flag\n",
    "x_test = df_test.drop('flag', axis=1)\n",
    "y_test = df_test.flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8922419",
   "metadata": {},
   "source": [
    "rf =  RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2405d",
   "metadata": {},
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1dd9f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e5310107",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e153054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016150e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493a1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314c917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dd0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10d477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3aa131d",
   "metadata": {},
   "source": [
    "# готовый скрипт "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac83ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь до данных на компьютере\n",
    "path = 'train_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0494bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",
    "                                     num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    читает num_parts_to_read партиций, преобразовывает их к pd.DataFrame и возвращает\n",
    "    :param path_to_dataset: путь до директории с партициями\n",
    "    :param start_from: номер партиции, с которой нужно начать чтение\n",
    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",
    "    :param columns: список колонок, которые нужно прочитать из партиции\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset)\n",
    "                              if filename.startswith('train')])\n",
    "    print(dataset_paths)\n",
    "\n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "    if verbose:\n",
    "        print('Reading chunks:\\n')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "    for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        print('chunk_path', chunk_path)\n",
    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",
    "        res.append(chunk)\n",
    "\n",
    "    return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6fa08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers\n",
    "check = []\n",
    "for i in range(len(answers)-1):\n",
    "#     if i == \n",
    "    check.append(answers.id[i]+1 == answers.id[i+1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
