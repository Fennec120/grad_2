{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8849230",
   "metadata": {},
   "source": [
    "# ooookay you motherfuckers!\n",
    "lets roll!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e9fca",
   "metadata": {},
   "source": [
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b70e74",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"xyi\") \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bfb46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f98067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_df(part):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    # open\n",
    "    df = pd.read_csv('train_data/tst_'+str(part)+'.csv', header=None)\n",
    "    \n",
    "    # очень неудобные названия\n",
    "    col_names = dict()\n",
    "    for i in range(len(df.columns)):\n",
    "                       col_names[df.columns[i]] = cols[i]\n",
    "    df = df.rename(columns=col_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16754c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df(df3, total_rows =  100000, neg_percent = 50, pos_percent = 50):\n",
    "    print( 'sample_df3 start')\n",
    "    df3_pos = df3[df3['flag'] == 1].sample(int(total_rows / 100 * pos_percent))\n",
    "    df3_neg = df3[df3['flag'] == 0].sample(int(total_rows / 100 * neg_percent))\n",
    "    df3_pos = df3_pos.reset_index()\n",
    "    df3_neg = df3_neg.reset_index()\n",
    "    df3_pos = df3_pos.drop('index', axis=1)\n",
    "    df3_neg = df3_neg.drop('index', axis=1)\n",
    "    df3 = pd.concat([df3_pos, df3_neg])\n",
    "    \n",
    "    print( 'sample_df3 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb8925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['id',\n",
    " 'rn',\n",
    " 'pre_since_opened',\n",
    " 'pre_since_confirmed',\n",
    " 'pre_pterm',\n",
    " 'pre_fterm',\n",
    " 'pre_till_pclose',\n",
    " 'pre_till_fclose',\n",
    " 'pre_loans_credit_limit',\n",
    " 'pre_loans_next_pay_summ',\n",
    " 'pre_loans_outstanding',\n",
    " 'pre_loans_total_overdue',\n",
    " 'pre_loans_max_overdue_sum',\n",
    " 'pre_loans_credit_cost_rate',\n",
    " 'pre_loans5',\n",
    " 'pre_loans530',\n",
    " 'pre_loans3060',\n",
    " 'pre_loans6090',\n",
    " 'pre_loans90',\n",
    " 'is_zero_loans5',\n",
    " 'is_zero_loans530',\n",
    " 'is_zero_loans3060',\n",
    " 'is_zero_loans6090',\n",
    " 'is_zero_loans90',\n",
    " 'pre_util',\n",
    " 'pre_over2limit',\n",
    " 'pre_maxover2limit',\n",
    " 'is_zero_util',\n",
    " 'is_zero_over2limit',\n",
    " 'is_zero_maxover2limit',\n",
    " 'enc_paym_0',\n",
    " 'enc_paym_1',\n",
    " 'enc_paym_2',\n",
    " 'enc_paym_3',\n",
    " 'enc_paym_4',\n",
    " 'enc_paym_5',\n",
    " 'enc_paym_6',\n",
    " 'enc_paym_7',\n",
    " 'enc_paym_8',\n",
    " 'enc_paym_9',\n",
    " 'enc_paym_10',\n",
    " 'enc_paym_11',\n",
    " 'enc_paym_12',\n",
    " 'enc_paym_13',\n",
    " 'enc_paym_14',\n",
    " 'enc_paym_15',\n",
    " 'enc_paym_16',\n",
    " 'enc_paym_17',\n",
    " 'enc_paym_18',\n",
    " 'enc_paym_19',\n",
    " 'enc_paym_20',\n",
    " 'enc_paym_21',\n",
    " 'enc_paym_22',\n",
    " 'enc_paym_23',\n",
    " 'enc_paym_24',\n",
    " 'enc_loans_account_holder_type',\n",
    " 'enc_loans_credit_status',\n",
    " 'enc_loans_credit_type',\n",
    " 'enc_loans_account_cur',\n",
    " 'pclose_flag',\n",
    " 'fclose_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb35835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_df(0)\n",
    "# df2 = open_df(1)\n",
    "# df3 = open_df(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2644df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv('train_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba5a06bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03678585326438938"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.flag.value_counts()[1] / answers.flag.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83391389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2893558\n",
       "1     106442\n",
       "Name: flag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7dde81",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff6ab830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'flag'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09d4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, answers, on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84bff417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_df3 start\n",
      "sample_df3 end\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "df_balanced = sample_df(df, 100000, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b4697",
   "metadata": {},
   "source": [
    "sns.heatmap(df_balanced.corr(), cmap='coolwarm', linewidths=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "481511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_balanced.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2afa151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_corr.columns\n",
    "rows = df_corr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4b59dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = []\n",
    "for col in columns:\n",
    "    corrs.append((df_balanced.flag.corr(df_balanced[col]), col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24693634",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = corrs[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70dee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in corrs:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b477b487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565579853950436"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr.loc['enc_paym_22', 'enc_paym_23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03717089",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = df.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ee04583",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df[['flag', 'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5088e5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    flag  id\n",
       "42     0   4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[check.id == 4 ]#.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213a9f4",
   "metadata": {},
   "source": [
    "positive_ids = []\n",
    "check = df[['flag', 'id']]\n",
    "for entry in id_list:\n",
    "    print(entry)\n",
    "    if check[check.id == entry ].iloc[0,0] == 1:\n",
    "        positive_ids.append(1)\n",
    "positive_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2975e",
   "metadata": {},
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4e17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030936"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(positive_ids) / len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df676ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_balanced, stratify=df_balanced['flag'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8395146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop('flag', axis=1)\n",
    "y_train = df_train.flag\n",
    "x_test = df_test.drop('flag', axis=1)\n",
    "y_test = df_test.flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8922419",
   "metadata": {},
   "source": [
    "rf =  RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2405d",
   "metadata": {},
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1dd9f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c156eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6de5f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae2d3d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc6704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61e318e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score acc -  1.0\n",
      "test score acc -  0.6074\n",
      "train score roc -  1.0\n",
      "test score roc -  0.6484391444444444\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "pred_test = model.predict(x_test)\n",
    "print('train score acc - ', accuracy_score(y_train, pred_train))\n",
    "print('test score acc - ', accuracy_score(y_test, pred_test))\n",
    "\n",
    "prob_train = model.predict_proba(x_train)[:, 1]\n",
    "prob_test = model.predict_proba(x_test)[:, 1]\n",
    "print('train score roc - ', roc_auc_score(y_train, prob_train))\n",
    "print('test score roc - ', roc_auc_score(y_test, prob_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "340d2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# неправдоподобно высокие показатели, попробуем другую метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc034c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = open_df(1)\n",
    "df2 = pd.merge(df2, answers, on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95b7f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df2.drop('flag', axis=1)\n",
    "y_train = df2.flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42aa26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score acc -  0.6884236926750582\n",
      "train score roc -  0.6235708113707962\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "print('train score acc - ', accuracy_score(y_train, pred_train))\n",
    "\n",
    "prob_train = model.predict_proba(x_train)[:, 1]\n",
    "print('train score roc - ', roc_auc_score(y_train, prob_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ea00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e42a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Score: 0.6586614683736624\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search using Random Forest Classifier\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a07a19e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49930566, 0.50069434],\n",
       "       [0.49827974, 0.50172026],\n",
       "       [0.49695717, 0.50304283],\n",
       "       ...,\n",
       "       [0.49686093, 0.50313907],\n",
       "       [0.49893878, 0.50106122],\n",
       "       [0.49670406, 0.50329594]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2182b067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787aa48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e620b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748a1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccadfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('train_data/tst_1.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e82669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2107305, 61)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3dbeaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# очень неудобные названия\n",
    "col_names = dict()\n",
    "for i in range(len(df2.columns)):\n",
    "                   col_names[df2.columns[i]] = cols[i]\n",
    "df2 = df2.rename(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2375f32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "250000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:answers_dict[x])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:answers_dict[x])\n",
      "\u001b[1;31mKeyError\u001b[0m: 250000"
     ]
    }
   ],
   "source": [
    "df2['flag'] = df2.id.apply(lambda x:answers_dict[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_train, df2_test = train_test_split(df2, stratify=df2['flag'], test_size=0.3)\n",
    "x2_train = df2_train.drop('flag', axis=1)\n",
    "y2_train = df2_train.flag\n",
    "x2_test = df2_test.drop('flag', axis=1)\n",
    "y2_test = df2_test.flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2_train = lr.predict(x2_train)\n",
    "pred2_test = lr.predict(x2_test)\n",
    "print('train score - ', accuracy_score(y2_train, pred2_train))\n",
    "print('test score - ', accuracy_score(y2_test, pred2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for entry in pred2_test:\n",
    "    if entry == 1:\n",
    "        counter +=1\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493a1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314c917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dd0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10d477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828f686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac83ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь до данных на компьютере\n",
    "path = 'train_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0494bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",
    "                                     num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    читает num_parts_to_read партиций, преобразовывает их к pd.DataFrame и возвращает\n",
    "    :param path_to_dataset: путь до директории с партициями\n",
    "    :param start_from: номер партиции, с которой нужно начать чтение\n",
    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",
    "    :param columns: список колонок, которые нужно прочитать из партиции\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset)\n",
    "                              if filename.startswith('train')])\n",
    "    print(dataset_paths)\n",
    "\n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "    if verbose:\n",
    "        print('Reading chunks:\\n')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "    for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        print('chunk_path', chunk_path)\n",
    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",
    "        res.append(chunk)\n",
    "\n",
    "    return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79140355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a20786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ee0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2891db7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6fa08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers\n",
    "check = []\n",
    "for i in range(len(answers)-1):\n",
    "#     if i == \n",
    "    check.append(answers.id[i]+1 == answers.id[i+1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
